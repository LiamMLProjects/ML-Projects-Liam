{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e5e133bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "\n",
    "def sigmoid(z):\n",
    "    return 1.0 / (1 + np.exp(-z))\n",
    "\n",
    "\n",
    "def sigmoid_derivative(z):\n",
    "    return sigmoid(z) * (1.0 - sigmoid(z))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d3b54b76",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(X, y, n_hidden, learning_rate, n_iter):\n",
    "    m, n_input = X.shape\n",
    "    W1 = np.random.randn(n_input, n_hidden)\n",
    "    b1 = np.zeros((1, n_hidden))\n",
    "    W2 = np.random.randn(n_hidden, 1)\n",
    "    b2 = np.zeros((1, 1))\n",
    "    for i in range(1, n_iter+1):\n",
    "        Z2 = np.matmul(X, W1) + b1\n",
    "        A2 = sigmoid(Z2)\n",
    "        Z3 = np.matmul(A2, W2) + b2\n",
    "        A3 = Z3\n",
    "\n",
    "        dZ3 = A3 - y\n",
    "        dW2 = np.matmul(A2.T, dZ3)\n",
    "        db2 = np.sum(dZ3, axis=0, keepdims=True)\n",
    "\n",
    "        dZ2 = np.matmul(dZ3, W2.T) * sigmoid_derivative(Z2)\n",
    "        dW1 = np.matmul(X.T, dZ2)\n",
    "        db1 = np.sum(dZ2, axis=0)\n",
    "\n",
    "        W2 = W2 - learning_rate * dW2 / m\n",
    "        b2 = b2 - learning_rate * db2 / m\n",
    "        W1 = W1 - learning_rate * dW1 / m\n",
    "        b1 = b1 - learning_rate * db1 / m\n",
    "\n",
    "        if i % 100 == 0:\n",
    "            cost = np.mean((y - A3) ** 2)\n",
    "            print('Iteration %i, training loss: %f' % (i, cost))\n",
    "\n",
    "    model = {'W1': W1, 'b1': b1, 'W2': W2, 'b2': b2}\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4815798c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(x, model):\n",
    "    W1 = model['W1']\n",
    "    b1 = model['b1']\n",
    "    W2 = model['W2']\n",
    "    b2 = model['b2']\n",
    "    A2 = sigmoid(np.matmul(x, W1) + b1)\n",
    "    A3 = np.matmul(A2, W2) + b2\n",
    "    return A3\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1b6811ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import datasets\n",
    "diabetes = datasets.load_diabetes()\n",
    "num_test = 10  # the last 10 samples as testing set\n",
    "\n",
    "from sklearn import preprocessing\n",
    "scaler = preprocessing.StandardScaler()\n",
    "\n",
    "X_train = diabetes.data[:-num_test, :]\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "y_train = diabetes.target[:-num_test].reshape(-1, 1)\n",
    "X_test = diabetes.data[-num_test:, :]\n",
    "X_test = scaler.transform(X_test)\n",
    "y_test = diabetes.target[-num_test:]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e182aacb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 100, training loss: 1998.296076\n",
      "Iteration 200, training loss: 1814.342820\n",
      "Iteration 300, training loss: 1690.890405\n",
      "Iteration 400, training loss: 1559.154455\n",
      "Iteration 500, training loss: 1403.650066\n",
      "Iteration 600, training loss: 1318.148151\n",
      "Iteration 700, training loss: 1259.770287\n",
      "Iteration 800, training loss: 1218.458298\n",
      "Iteration 900, training loss: 1185.399699\n",
      "Iteration 1000, training loss: 1154.183768\n",
      "Iteration 1100, training loss: 1127.510297\n",
      "Iteration 1200, training loss: 1113.659336\n",
      "Iteration 1300, training loss: 1105.944286\n",
      "Iteration 1400, training loss: 1086.427980\n",
      "Iteration 1500, training loss: 1077.013574\n",
      "Iteration 1600, training loss: 1058.585169\n",
      "Iteration 1700, training loss: 1051.573096\n",
      "Iteration 1800, training loss: 1043.471946\n",
      "Iteration 1900, training loss: 1035.452119\n",
      "Iteration 2000, training loss: 1027.459190\n",
      "[[261.23212844]\n",
      " [ 56.39117046]\n",
      " [ 96.85606368]\n",
      " [115.55683243]\n",
      " [ 89.54313034]\n",
      " [160.34783525]\n",
      " [ 95.03197958]\n",
      " [ 47.82868686]\n",
      " [222.2577584 ]\n",
      " [ 51.08481396]]\n",
      "[173.  72.  49.  64.  48. 178. 104. 132. 220.  57.]\n"
     ]
    }
   ],
   "source": [
    "n_hidden = 20\n",
    "learning_rate = 0.1\n",
    "n_iter = 2000\n",
    "\n",
    "model = train(X_train, y_train, n_hidden, learning_rate, n_iter)\n",
    "predictions = predict(X_test, model)\n",
    "print(predictions)\n",
    "print(y_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "566cb748",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/liamalkhatib/opt/anaconda3/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:1625: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[233.49585182  68.18407781 119.3049426  122.25921605  66.1200858\n",
      " 200.91764911  96.21982821 110.48092428 203.04431421  74.04628986]\n",
      "1396.6459679497505\n"
     ]
    }
   ],
   "source": [
    "# Scikit-learn implementation of neural network\n",
    "\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "nn_scikit = MLPRegressor(hidden_layer_sizes=(16, 8), activation='relu', solver='adam',\n",
    "                         learning_rate_init=0.001, random_state=42, max_iter=2000)\n",
    "nn_scikit.fit(X_train, y_train)\n",
    "predictions = nn_scikit.predict(X_test)\n",
    "print(predictions)\n",
    "print(np.mean((y_test - predictions) ** 2))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f36e51d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-08-06 20:22:00.423454: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "# TensorFlow implementation of neural network\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "\n",
    "tf.random.set_seed(42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a2ec4938",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.Sequential([\n",
    "    keras.layers.Dense(units=20, activation='relu'),\n",
    "    keras.layers.Dense(units=8, activation='relu'),\n",
    "    keras.layers.Dense(units=1)\n",
    "])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "04264e66",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='mean_squared_error',\n",
    "              optimizer=tf.keras.optimizers.Adam(0.02))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1761059e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/300\n",
      "14/14 [==============================] - 1s 712us/step - loss: 28394.8398\n",
      "Epoch 2/300\n",
      "14/14 [==============================] - 0s 581us/step - loss: 21179.0078\n",
      "Epoch 3/300\n",
      "14/14 [==============================] - 0s 596us/step - loss: 8901.2998\n",
      "Epoch 4/300\n",
      "14/14 [==============================] - 0s 594us/step - loss: 5959.0059\n",
      "Epoch 5/300\n",
      "14/14 [==============================] - 0s 652us/step - loss: 4234.1577\n",
      "Epoch 6/300\n",
      "14/14 [==============================] - 0s 649us/step - loss: 3609.6855\n",
      "Epoch 7/300\n",
      "14/14 [==============================] - 0s 7ms/step - loss: 3255.4590\n",
      "Epoch 8/300\n",
      "14/14 [==============================] - 0s 557us/step - loss: 3082.1951\n",
      "Epoch 9/300\n",
      "14/14 [==============================] - 0s 628us/step - loss: 2912.7988\n",
      "Epoch 10/300\n",
      "14/14 [==============================] - 0s 593us/step - loss: 2890.9697\n",
      "Epoch 11/300\n",
      "14/14 [==============================] - 0s 717us/step - loss: 2868.4124\n",
      "Epoch 12/300\n",
      "14/14 [==============================] - 0s 701us/step - loss: 2783.4441\n",
      "Epoch 13/300\n",
      "14/14 [==============================] - 0s 628us/step - loss: 2797.2410\n",
      "Epoch 14/300\n",
      "14/14 [==============================] - 0s 660us/step - loss: 2756.8027\n",
      "Epoch 15/300\n",
      "14/14 [==============================] - 0s 712us/step - loss: 2737.2593\n",
      "Epoch 16/300\n",
      "14/14 [==============================] - 0s 637us/step - loss: 2714.3447\n",
      "Epoch 17/300\n",
      "14/14 [==============================] - 0s 684us/step - loss: 2707.4780\n",
      "Epoch 18/300\n",
      "14/14 [==============================] - 0s 743us/step - loss: 2704.9875\n",
      "Epoch 19/300\n",
      "14/14 [==============================] - 0s 718us/step - loss: 2684.1904\n",
      "Epoch 20/300\n",
      "14/14 [==============================] - 0s 664us/step - loss: 2660.9468\n",
      "Epoch 21/300\n",
      "14/14 [==============================] - 0s 703us/step - loss: 2670.2332\n",
      "Epoch 22/300\n",
      "14/14 [==============================] - 0s 619us/step - loss: 2654.6230\n",
      "Epoch 23/300\n",
      "14/14 [==============================] - 0s 629us/step - loss: 2650.9856\n",
      "Epoch 24/300\n",
      "14/14 [==============================] - 0s 688us/step - loss: 2609.6719\n",
      "Epoch 25/300\n",
      "14/14 [==============================] - 0s 605us/step - loss: 2621.2473\n",
      "Epoch 26/300\n",
      "14/14 [==============================] - 0s 629us/step - loss: 2615.0159\n",
      "Epoch 27/300\n",
      "14/14 [==============================] - 0s 665us/step - loss: 2619.2209\n",
      "Epoch 28/300\n",
      "14/14 [==============================] - 0s 600us/step - loss: 2610.1260\n",
      "Epoch 29/300\n",
      "14/14 [==============================] - 0s 707us/step - loss: 2595.3386\n",
      "Epoch 30/300\n",
      "14/14 [==============================] - 0s 621us/step - loss: 2611.6504\n",
      "Epoch 31/300\n",
      "14/14 [==============================] - 0s 636us/step - loss: 2625.7556\n",
      "Epoch 32/300\n",
      "14/14 [==============================] - 0s 672us/step - loss: 2585.1082\n",
      "Epoch 33/300\n",
      "14/14 [==============================] - 0s 612us/step - loss: 2590.2520\n",
      "Epoch 34/300\n",
      "14/14 [==============================] - 0s 687us/step - loss: 2537.9407\n",
      "Epoch 35/300\n",
      "14/14 [==============================] - 0s 674us/step - loss: 2630.5269\n",
      "Epoch 36/300\n",
      "14/14 [==============================] - 0s 605us/step - loss: 2597.2502\n",
      "Epoch 37/300\n",
      "14/14 [==============================] - 0s 690us/step - loss: 2607.4067\n",
      "Epoch 38/300\n",
      "14/14 [==============================] - 0s 632us/step - loss: 2553.2073\n",
      "Epoch 39/300\n",
      "14/14 [==============================] - 0s 605us/step - loss: 2545.8169\n",
      "Epoch 40/300\n",
      "14/14 [==============================] - 0s 663us/step - loss: 2586.7285\n",
      "Epoch 41/300\n",
      "14/14 [==============================] - 0s 601us/step - loss: 2588.4177\n",
      "Epoch 42/300\n",
      "14/14 [==============================] - 0s 611us/step - loss: 2628.5706\n",
      "Epoch 43/300\n",
      "14/14 [==============================] - 0s 664us/step - loss: 2536.8411\n",
      "Epoch 44/300\n",
      "14/14 [==============================] - 0s 592us/step - loss: 2548.3787\n",
      "Epoch 45/300\n",
      "14/14 [==============================] - 0s 697us/step - loss: 2514.0466\n",
      "Epoch 46/300\n",
      "14/14 [==============================] - 0s 607us/step - loss: 2499.5032\n",
      "Epoch 47/300\n",
      "14/14 [==============================] - 0s 644us/step - loss: 2536.7500\n",
      "Epoch 48/300\n",
      "14/14 [==============================] - 0s 662us/step - loss: 2493.6455\n",
      "Epoch 49/300\n",
      "14/14 [==============================] - 0s 595us/step - loss: 2497.4746\n",
      "Epoch 50/300\n",
      "14/14 [==============================] - 0s 660us/step - loss: 2508.6313\n",
      "Epoch 51/300\n",
      "14/14 [==============================] - 0s 670us/step - loss: 2494.8096\n",
      "Epoch 52/300\n",
      "14/14 [==============================] - 0s 610us/step - loss: 2499.6187\n",
      "Epoch 53/300\n",
      "14/14 [==============================] - 0s 719us/step - loss: 2505.2471\n",
      "Epoch 54/300\n",
      "14/14 [==============================] - 0s 628us/step - loss: 2520.9717\n",
      "Epoch 55/300\n",
      "14/14 [==============================] - 0s 600us/step - loss: 2512.9766\n",
      "Epoch 56/300\n",
      "14/14 [==============================] - 0s 618us/step - loss: 2520.6140\n",
      "Epoch 57/300\n",
      "14/14 [==============================] - 0s 633us/step - loss: 2496.3259\n",
      "Epoch 58/300\n",
      "14/14 [==============================] - 0s 657us/step - loss: 2497.2537\n",
      "Epoch 59/300\n",
      "14/14 [==============================] - 0s 644us/step - loss: 2441.1558\n",
      "Epoch 60/300\n",
      "14/14 [==============================] - 0s 595us/step - loss: 2418.9465\n",
      "Epoch 61/300\n",
      "14/14 [==============================] - 0s 606us/step - loss: 2421.4163\n",
      "Epoch 62/300\n",
      "14/14 [==============================] - 0s 577us/step - loss: 2429.8799\n",
      "Epoch 63/300\n",
      "14/14 [==============================] - 0s 569us/step - loss: 2424.4802\n",
      "Epoch 64/300\n",
      "14/14 [==============================] - 0s 551us/step - loss: 2409.2834\n",
      "Epoch 65/300\n",
      "14/14 [==============================] - 0s 547us/step - loss: 2407.9927\n",
      "Epoch 66/300\n",
      "14/14 [==============================] - 0s 564us/step - loss: 2405.3152\n",
      "Epoch 67/300\n",
      "14/14 [==============================] - 0s 655us/step - loss: 2409.4336\n",
      "Epoch 68/300\n",
      "14/14 [==============================] - 0s 633us/step - loss: 2412.0000\n",
      "Epoch 69/300\n",
      "14/14 [==============================] - 0s 565us/step - loss: 2377.3474\n",
      "Epoch 70/300\n",
      "14/14 [==============================] - 0s 559us/step - loss: 2402.1843\n",
      "Epoch 71/300\n",
      "14/14 [==============================] - 0s 553us/step - loss: 2388.2529\n",
      "Epoch 72/300\n",
      "14/14 [==============================] - 0s 580us/step - loss: 2375.9299\n",
      "Epoch 73/300\n",
      "14/14 [==============================] - 0s 536us/step - loss: 2394.1040\n",
      "Epoch 74/300\n",
      "14/14 [==============================] - 0s 563us/step - loss: 2382.3691\n",
      "Epoch 75/300\n",
      "14/14 [==============================] - 0s 547us/step - loss: 2332.2224\n",
      "Epoch 76/300\n",
      "14/14 [==============================] - 0s 571us/step - loss: 2379.4187\n",
      "Epoch 77/300\n",
      "14/14 [==============================] - 0s 575us/step - loss: 2373.9106\n",
      "Epoch 78/300\n",
      "14/14 [==============================] - 0s 588us/step - loss: 2403.5134\n",
      "Epoch 79/300\n",
      "14/14 [==============================] - 0s 541us/step - loss: 2381.8101\n",
      "Epoch 80/300\n",
      "14/14 [==============================] - 0s 575us/step - loss: 2331.5642\n",
      "Epoch 81/300\n",
      "14/14 [==============================] - 0s 597us/step - loss: 2370.9336\n",
      "Epoch 82/300\n",
      "14/14 [==============================] - 0s 581us/step - loss: 2317.5005\n",
      "Epoch 83/300\n",
      "14/14 [==============================] - 0s 598us/step - loss: 2319.6914\n",
      "Epoch 84/300\n",
      "14/14 [==============================] - 0s 578us/step - loss: 2313.1855\n",
      "Epoch 85/300\n",
      "14/14 [==============================] - 0s 585us/step - loss: 2309.1626\n",
      "Epoch 86/300\n",
      "14/14 [==============================] - 0s 588us/step - loss: 2405.4739\n",
      "Epoch 87/300\n",
      "14/14 [==============================] - 0s 590us/step - loss: 2410.8303\n",
      "Epoch 88/300\n",
      "14/14 [==============================] - 0s 552us/step - loss: 2439.6287\n",
      "Epoch 89/300\n",
      "14/14 [==============================] - 0s 583us/step - loss: 2312.0081\n",
      "Epoch 90/300\n",
      "14/14 [==============================] - 0s 542us/step - loss: 2322.1973\n",
      "Epoch 91/300\n",
      "14/14 [==============================] - 0s 578us/step - loss: 2365.8181\n",
      "Epoch 92/300\n",
      "14/14 [==============================] - 0s 566us/step - loss: 2322.2295\n",
      "Epoch 93/300\n",
      "14/14 [==============================] - 0s 565us/step - loss: 2386.1174\n",
      "Epoch 94/300\n",
      "14/14 [==============================] - 0s 592us/step - loss: 2362.6343\n",
      "Epoch 95/300\n",
      "14/14 [==============================] - 0s 539us/step - loss: 2338.7471\n",
      "Epoch 96/300\n",
      "14/14 [==============================] - 0s 553us/step - loss: 2284.3154\n",
      "Epoch 97/300\n",
      "14/14 [==============================] - 0s 568us/step - loss: 2354.2981\n",
      "Epoch 98/300\n",
      "14/14 [==============================] - 0s 577us/step - loss: 2282.1282\n",
      "Epoch 99/300\n",
      "14/14 [==============================] - 0s 550us/step - loss: 2279.0898\n",
      "Epoch 100/300\n",
      "14/14 [==============================] - 0s 561us/step - loss: 2270.1975\n",
      "Epoch 101/300\n",
      "14/14 [==============================] - 0s 560us/step - loss: 2296.6853\n",
      "Epoch 102/300\n",
      "14/14 [==============================] - 0s 566us/step - loss: 2301.5486\n",
      "Epoch 103/300\n",
      "14/14 [==============================] - 0s 534us/step - loss: 2266.0657\n",
      "Epoch 104/300\n",
      "14/14 [==============================] - 0s 568us/step - loss: 2252.5864\n",
      "Epoch 105/300\n",
      "14/14 [==============================] - 0s 592us/step - loss: 2273.4294\n",
      "Epoch 106/300\n",
      "14/14 [==============================] - 0s 544us/step - loss: 2277.7031\n",
      "Epoch 107/300\n",
      "14/14 [==============================] - 0s 662us/step - loss: 2240.2048\n",
      "Epoch 108/300\n",
      "14/14 [==============================] - 0s 636us/step - loss: 2282.0051\n",
      "Epoch 109/300\n",
      "14/14 [==============================] - 0s 595us/step - loss: 2276.4045\n",
      "Epoch 110/300\n",
      "14/14 [==============================] - 0s 677us/step - loss: 2329.5110\n",
      "Epoch 111/300\n",
      "14/14 [==============================] - 0s 589us/step - loss: 2266.3259\n",
      "Epoch 112/300\n",
      "14/14 [==============================] - 0s 599us/step - loss: 2310.5647\n",
      "Epoch 113/300\n",
      "14/14 [==============================] - 0s 556us/step - loss: 2303.8943\n",
      "Epoch 114/300\n",
      "14/14 [==============================] - 0s 596us/step - loss: 2232.6265\n",
      "Epoch 115/300\n",
      "14/14 [==============================] - 0s 533us/step - loss: 2221.9026\n",
      "Epoch 116/300\n",
      "14/14 [==============================] - 0s 583us/step - loss: 2238.8982\n",
      "Epoch 117/300\n",
      "14/14 [==============================] - 0s 544us/step - loss: 2233.9324\n",
      "Epoch 118/300\n",
      "14/14 [==============================] - 0s 565us/step - loss: 2211.5854\n",
      "Epoch 119/300\n",
      "14/14 [==============================] - 0s 564us/step - loss: 2209.4785\n",
      "Epoch 120/300\n",
      "14/14 [==============================] - 0s 591us/step - loss: 2232.5095\n",
      "Epoch 121/300\n",
      "14/14 [==============================] - 0s 616us/step - loss: 2229.8254\n",
      "Epoch 122/300\n",
      "14/14 [==============================] - 0s 559us/step - loss: 2231.5071\n",
      "Epoch 123/300\n",
      "14/14 [==============================] - 0s 567us/step - loss: 2267.2878\n",
      "Epoch 124/300\n",
      "14/14 [==============================] - 0s 536us/step - loss: 2240.6975\n",
      "Epoch 125/300\n",
      "14/14 [==============================] - 0s 567us/step - loss: 2189.2686\n",
      "Epoch 126/300\n",
      "14/14 [==============================] - 0s 551us/step - loss: 2228.3765\n",
      "Epoch 127/300\n",
      "14/14 [==============================] - 0s 531us/step - loss: 2248.5725\n",
      "Epoch 128/300\n",
      "14/14 [==============================] - 0s 547us/step - loss: 2214.9436\n",
      "Epoch 129/300\n",
      "14/14 [==============================] - 0s 538us/step - loss: 2312.5759\n",
      "Epoch 130/300\n",
      "14/14 [==============================] - 0s 531us/step - loss: 2263.2070\n",
      "Epoch 131/300\n",
      "14/14 [==============================] - 0s 550us/step - loss: 2281.7820\n",
      "Epoch 132/300\n",
      "14/14 [==============================] - 0s 538us/step - loss: 2269.9211\n",
      "Epoch 133/300\n",
      "14/14 [==============================] - 0s 562us/step - loss: 2222.7676\n",
      "Epoch 134/300\n",
      "14/14 [==============================] - 0s 565us/step - loss: 2210.8950\n",
      "Epoch 135/300\n",
      "14/14 [==============================] - 0s 566us/step - loss: 2224.2720\n",
      "Epoch 136/300\n",
      "14/14 [==============================] - 0s 548us/step - loss: 2173.6553\n",
      "Epoch 137/300\n",
      "14/14 [==============================] - 0s 534us/step - loss: 2197.6833\n",
      "Epoch 138/300\n",
      "14/14 [==============================] - 0s 546us/step - loss: 2225.0916\n",
      "Epoch 139/300\n",
      "14/14 [==============================] - 0s 564us/step - loss: 2186.1875\n",
      "Epoch 140/300\n",
      "14/14 [==============================] - 0s 558us/step - loss: 2178.0464\n",
      "Epoch 141/300\n",
      "14/14 [==============================] - 0s 577us/step - loss: 2164.0273\n",
      "Epoch 142/300\n",
      "14/14 [==============================] - 0s 573us/step - loss: 2183.5818\n",
      "Epoch 143/300\n",
      "14/14 [==============================] - 0s 588us/step - loss: 2206.5525\n",
      "Epoch 144/300\n",
      "14/14 [==============================] - 0s 589us/step - loss: 2157.7361\n",
      "Epoch 145/300\n",
      "14/14 [==============================] - 0s 541us/step - loss: 2177.4314\n",
      "Epoch 146/300\n",
      "14/14 [==============================] - 0s 580us/step - loss: 2155.7185\n",
      "Epoch 147/300\n",
      "14/14 [==============================] - 0s 620us/step - loss: 2237.1470\n",
      "Epoch 148/300\n",
      "14/14 [==============================] - 0s 594us/step - loss: 2164.0122\n",
      "Epoch 149/300\n",
      "14/14 [==============================] - 0s 594us/step - loss: 2181.7317\n",
      "Epoch 150/300\n",
      "14/14 [==============================] - 0s 627us/step - loss: 2236.0999\n",
      "Epoch 151/300\n",
      "14/14 [==============================] - 0s 596us/step - loss: 2294.6912\n",
      "Epoch 152/300\n",
      "14/14 [==============================] - 0s 631us/step - loss: 2312.5586\n",
      "Epoch 153/300\n",
      "14/14 [==============================] - 0s 609us/step - loss: 2173.8374\n",
      "Epoch 154/300\n",
      "14/14 [==============================] - 0s 632us/step - loss: 2163.9333\n",
      "Epoch 155/300\n",
      "14/14 [==============================] - 0s 557us/step - loss: 2193.7678\n",
      "Epoch 156/300\n",
      "14/14 [==============================] - 0s 560us/step - loss: 2261.8972\n",
      "Epoch 157/300\n",
      "14/14 [==============================] - 0s 534us/step - loss: 2208.8979\n",
      "Epoch 158/300\n",
      "14/14 [==============================] - 0s 546us/step - loss: 2143.1504\n",
      "Epoch 159/300\n",
      "14/14 [==============================] - 0s 568us/step - loss: 2242.5911\n",
      "Epoch 160/300\n",
      "14/14 [==============================] - 0s 586us/step - loss: 2219.4756\n",
      "Epoch 161/300\n",
      "14/14 [==============================] - 0s 544us/step - loss: 2242.4431\n",
      "Epoch 162/300\n",
      "14/14 [==============================] - 0s 583us/step - loss: 2176.6768\n",
      "Epoch 163/300\n",
      "14/14 [==============================] - 0s 562us/step - loss: 2190.0676\n",
      "Epoch 164/300\n",
      "14/14 [==============================] - 0s 553us/step - loss: 2166.2732\n",
      "Epoch 165/300\n",
      "14/14 [==============================] - 0s 537us/step - loss: 2130.3406\n",
      "Epoch 166/300\n",
      "14/14 [==============================] - 0s 533us/step - loss: 2148.0784\n",
      "Epoch 167/300\n",
      "14/14 [==============================] - 0s 536us/step - loss: 2117.8511\n",
      "Epoch 168/300\n",
      "14/14 [==============================] - 0s 535us/step - loss: 2150.3589\n",
      "Epoch 169/300\n",
      "14/14 [==============================] - 0s 540us/step - loss: 2156.5637\n",
      "Epoch 170/300\n",
      "14/14 [==============================] - 0s 564us/step - loss: 2194.4763\n",
      "Epoch 171/300\n",
      "14/14 [==============================] - 0s 551us/step - loss: 2254.1721\n",
      "Epoch 172/300\n",
      "14/14 [==============================] - 0s 544us/step - loss: 2247.9502\n",
      "Epoch 173/300\n",
      "14/14 [==============================] - 0s 535us/step - loss: 2160.4636\n",
      "Epoch 174/300\n",
      "14/14 [==============================] - 0s 531us/step - loss: 2101.2195\n",
      "Epoch 175/300\n",
      "14/14 [==============================] - 0s 541us/step - loss: 2112.3394\n",
      "Epoch 176/300\n",
      "14/14 [==============================] - 0s 585us/step - loss: 2180.6462\n",
      "Epoch 177/300\n",
      "14/14 [==============================] - 0s 576us/step - loss: 2169.2986\n",
      "Epoch 178/300\n",
      "14/14 [==============================] - 0s 607us/step - loss: 2155.7439\n",
      "Epoch 179/300\n",
      "14/14 [==============================] - 0s 619us/step - loss: 2101.5347\n",
      "Epoch 180/300\n",
      "14/14 [==============================] - 0s 653us/step - loss: 2081.7310\n",
      "Epoch 181/300\n",
      "14/14 [==============================] - 0s 592us/step - loss: 2109.8037\n",
      "Epoch 182/300\n",
      "14/14 [==============================] - 0s 618us/step - loss: 2113.2375\n",
      "Epoch 183/300\n",
      "14/14 [==============================] - 0s 551us/step - loss: 2159.3796\n",
      "Epoch 184/300\n",
      "14/14 [==============================] - 0s 559us/step - loss: 2084.5088\n",
      "Epoch 185/300\n",
      "14/14 [==============================] - 0s 555us/step - loss: 2103.2009\n",
      "Epoch 186/300\n",
      "14/14 [==============================] - 0s 596us/step - loss: 2064.5107\n",
      "Epoch 187/300\n",
      "14/14 [==============================] - 0s 560us/step - loss: 2069.8745\n",
      "Epoch 188/300\n",
      "14/14 [==============================] - 0s 584us/step - loss: 2065.7605\n",
      "Epoch 189/300\n",
      "14/14 [==============================] - 0s 604us/step - loss: 2101.1794\n",
      "Epoch 190/300\n",
      "14/14 [==============================] - 0s 556us/step - loss: 2093.1189\n",
      "Epoch 191/300\n",
      "14/14 [==============================] - 0s 549us/step - loss: 2142.8677\n",
      "Epoch 192/300\n",
      "14/14 [==============================] - 0s 569us/step - loss: 2084.9724\n",
      "Epoch 193/300\n",
      "14/14 [==============================] - 0s 566us/step - loss: 2088.3691\n",
      "Epoch 194/300\n",
      "14/14 [==============================] - 0s 553us/step - loss: 2148.8027\n",
      "Epoch 195/300\n",
      "14/14 [==============================] - 0s 566us/step - loss: 2091.1582\n",
      "Epoch 196/300\n",
      "14/14 [==============================] - 0s 556us/step - loss: 2185.7021\n",
      "Epoch 197/300\n",
      "14/14 [==============================] - 0s 549us/step - loss: 2113.8708\n",
      "Epoch 198/300\n",
      "14/14 [==============================] - 0s 556us/step - loss: 2006.1849\n",
      "Epoch 199/300\n",
      "14/14 [==============================] - 0s 561us/step - loss: 2087.4121\n",
      "Epoch 200/300\n",
      "14/14 [==============================] - 0s 561us/step - loss: 2069.5576\n",
      "Epoch 201/300\n",
      "14/14 [==============================] - 0s 529us/step - loss: 2161.4309\n",
      "Epoch 202/300\n",
      "14/14 [==============================] - 0s 538us/step - loss: 2065.4785\n",
      "Epoch 203/300\n",
      "14/14 [==============================] - 0s 542us/step - loss: 2020.1697\n",
      "Epoch 204/300\n",
      "14/14 [==============================] - 0s 536us/step - loss: 2016.2086\n",
      "Epoch 205/300\n",
      "14/14 [==============================] - 0s 540us/step - loss: 2036.1072\n",
      "Epoch 206/300\n",
      "14/14 [==============================] - 0s 532us/step - loss: 2037.0896\n",
      "Epoch 207/300\n",
      "14/14 [==============================] - 0s 540us/step - loss: 2081.6675\n",
      "Epoch 208/300\n",
      "14/14 [==============================] - 0s 534us/step - loss: 2068.3481\n",
      "Epoch 209/300\n",
      "14/14 [==============================] - 0s 531us/step - loss: 2056.9971\n",
      "Epoch 210/300\n",
      "14/14 [==============================] - 0s 545us/step - loss: 2062.1787\n",
      "Epoch 211/300\n",
      "14/14 [==============================] - 0s 537us/step - loss: 2024.2435\n",
      "Epoch 212/300\n",
      "14/14 [==============================] - 0s 533us/step - loss: 2052.9858\n",
      "Epoch 213/300\n",
      "14/14 [==============================] - 0s 536us/step - loss: 2033.6099\n",
      "Epoch 214/300\n",
      "14/14 [==============================] - 0s 541us/step - loss: 2138.9446\n",
      "Epoch 215/300\n",
      "14/14 [==============================] - 0s 572us/step - loss: 2084.2920\n",
      "Epoch 216/300\n",
      "14/14 [==============================] - 0s 545us/step - loss: 2067.2493\n",
      "Epoch 217/300\n",
      "14/14 [==============================] - 0s 543us/step - loss: 2089.3154\n",
      "Epoch 218/300\n",
      "14/14 [==============================] - 0s 526us/step - loss: 2090.8110\n",
      "Epoch 219/300\n",
      "14/14 [==============================] - 0s 567us/step - loss: 2002.9703\n",
      "Epoch 220/300\n",
      "14/14 [==============================] - 0s 539us/step - loss: 2000.7455\n",
      "Epoch 221/300\n",
      "14/14 [==============================] - 0s 563us/step - loss: 2030.4161\n",
      "Epoch 222/300\n",
      "14/14 [==============================] - 0s 560us/step - loss: 2040.3309\n",
      "Epoch 223/300\n",
      "14/14 [==============================] - 0s 553us/step - loss: 2000.3711\n",
      "Epoch 224/300\n",
      "14/14 [==============================] - 0s 545us/step - loss: 1984.4712\n",
      "Epoch 225/300\n",
      "14/14 [==============================] - 0s 555us/step - loss: 2096.0037\n",
      "Epoch 226/300\n",
      "14/14 [==============================] - 0s 616us/step - loss: 2014.6570\n",
      "Epoch 227/300\n",
      "14/14 [==============================] - 0s 604us/step - loss: 2008.4594\n",
      "Epoch 228/300\n",
      "14/14 [==============================] - 0s 562us/step - loss: 2159.4192\n",
      "Epoch 229/300\n",
      "14/14 [==============================] - 0s 552us/step - loss: 2072.2183\n",
      "Epoch 230/300\n",
      "14/14 [==============================] - 0s 576us/step - loss: 1993.0687\n",
      "Epoch 231/300\n",
      "14/14 [==============================] - 0s 560us/step - loss: 2014.3718\n",
      "Epoch 232/300\n",
      "14/14 [==============================] - 0s 563us/step - loss: 2043.3661\n",
      "Epoch 233/300\n",
      "14/14 [==============================] - 0s 564us/step - loss: 2118.2024\n",
      "Epoch 234/300\n",
      "14/14 [==============================] - 0s 594us/step - loss: 2009.5392\n",
      "Epoch 235/300\n",
      "14/14 [==============================] - 0s 577us/step - loss: 2001.1635\n",
      "Epoch 236/300\n",
      "14/14 [==============================] - 0s 553us/step - loss: 2005.9834\n",
      "Epoch 237/300\n",
      "14/14 [==============================] - 0s 556us/step - loss: 2041.7064\n",
      "Epoch 238/300\n",
      "14/14 [==============================] - 0s 545us/step - loss: 2088.6216\n",
      "Epoch 239/300\n",
      "14/14 [==============================] - 0s 606us/step - loss: 2028.2241\n",
      "Epoch 240/300\n",
      "14/14 [==============================] - 0s 567us/step - loss: 2054.3408\n",
      "Epoch 241/300\n",
      "14/14 [==============================] - 0s 571us/step - loss: 2127.9067\n",
      "Epoch 242/300\n",
      "14/14 [==============================] - 0s 551us/step - loss: 2191.0901\n",
      "Epoch 243/300\n",
      "14/14 [==============================] - 0s 569us/step - loss: 2025.0709\n",
      "Epoch 244/300\n",
      "14/14 [==============================] - 0s 559us/step - loss: 1975.4315\n",
      "Epoch 245/300\n",
      "14/14 [==============================] - 0s 558us/step - loss: 2012.3553\n",
      "Epoch 246/300\n",
      "14/14 [==============================] - 0s 550us/step - loss: 1967.3423\n",
      "Epoch 247/300\n",
      "14/14 [==============================] - 0s 541us/step - loss: 2000.6732\n",
      "Epoch 248/300\n",
      "14/14 [==============================] - 0s 542us/step - loss: 1985.2594\n",
      "Epoch 249/300\n",
      "14/14 [==============================] - 0s 538us/step - loss: 1951.9084\n",
      "Epoch 250/300\n",
      "14/14 [==============================] - 0s 548us/step - loss: 2061.0146\n",
      "Epoch 251/300\n",
      "14/14 [==============================] - 0s 541us/step - loss: 2009.2101\n",
      "Epoch 252/300\n",
      "14/14 [==============================] - 0s 554us/step - loss: 2006.8486\n",
      "Epoch 253/300\n",
      "14/14 [==============================] - 0s 566us/step - loss: 1978.9810\n",
      "Epoch 254/300\n",
      "14/14 [==============================] - 0s 575us/step - loss: 1960.3525\n",
      "Epoch 255/300\n",
      "14/14 [==============================] - 0s 575us/step - loss: 2004.0151\n",
      "Epoch 256/300\n",
      "14/14 [==============================] - 0s 636us/step - loss: 2037.5177\n",
      "Epoch 257/300\n",
      "14/14 [==============================] - 0s 540us/step - loss: 2066.0205\n",
      "Epoch 258/300\n",
      "14/14 [==============================] - 0s 580us/step - loss: 2091.6162\n",
      "Epoch 259/300\n",
      "14/14 [==============================] - 0s 608us/step - loss: 1973.7701\n",
      "Epoch 260/300\n",
      "14/14 [==============================] - 0s 587us/step - loss: 1960.1143\n",
      "Epoch 261/300\n",
      "14/14 [==============================] - 0s 614us/step - loss: 1943.4464\n",
      "Epoch 262/300\n",
      "14/14 [==============================] - 0s 592us/step - loss: 1977.3579\n",
      "Epoch 263/300\n",
      "14/14 [==============================] - 0s 579us/step - loss: 1989.5858\n",
      "Epoch 264/300\n",
      "14/14 [==============================] - 0s 595us/step - loss: 1995.8585\n",
      "Epoch 265/300\n",
      "14/14 [==============================] - 0s 566us/step - loss: 1985.2053\n",
      "Epoch 266/300\n",
      "14/14 [==============================] - 0s 545us/step - loss: 1968.7357\n",
      "Epoch 267/300\n",
      "14/14 [==============================] - 0s 570us/step - loss: 1944.1471\n",
      "Epoch 268/300\n",
      "14/14 [==============================] - 0s 562us/step - loss: 1943.5408\n",
      "Epoch 269/300\n",
      "14/14 [==============================] - 0s 564us/step - loss: 1932.6670\n",
      "Epoch 270/300\n",
      "14/14 [==============================] - 0s 556us/step - loss: 1923.0330\n",
      "Epoch 271/300\n",
      "14/14 [==============================] - 0s 535us/step - loss: 2082.2693\n",
      "Epoch 272/300\n",
      "14/14 [==============================] - 0s 538us/step - loss: 2017.5416\n",
      "Epoch 273/300\n",
      "14/14 [==============================] - 0s 583us/step - loss: 1931.4584\n",
      "Epoch 274/300\n",
      "14/14 [==============================] - 0s 546us/step - loss: 1914.7213\n",
      "Epoch 275/300\n",
      "14/14 [==============================] - 0s 569us/step - loss: 1948.2329\n",
      "Epoch 276/300\n",
      "14/14 [==============================] - 0s 649us/step - loss: 1961.6697\n",
      "Epoch 277/300\n",
      "14/14 [==============================] - 0s 607us/step - loss: 1972.3099\n",
      "Epoch 278/300\n",
      "14/14 [==============================] - 0s 596us/step - loss: 1911.8905\n",
      "Epoch 279/300\n",
      "14/14 [==============================] - 0s 626us/step - loss: 1947.9329\n",
      "Epoch 280/300\n",
      "14/14 [==============================] - 0s 560us/step - loss: 1992.7998\n",
      "Epoch 281/300\n",
      "14/14 [==============================] - 0s 564us/step - loss: 1974.8875\n",
      "Epoch 282/300\n",
      "14/14 [==============================] - 0s 553us/step - loss: 1957.6298\n",
      "Epoch 283/300\n",
      "14/14 [==============================] - 0s 606us/step - loss: 1930.8179\n",
      "Epoch 284/300\n",
      "14/14 [==============================] - 0s 569us/step - loss: 1917.0122\n",
      "Epoch 285/300\n",
      "14/14 [==============================] - 0s 576us/step - loss: 1941.0724\n",
      "Epoch 286/300\n",
      "14/14 [==============================] - 0s 538us/step - loss: 1910.3268\n",
      "Epoch 287/300\n",
      "14/14 [==============================] - 0s 568us/step - loss: 1960.0760\n",
      "Epoch 288/300\n",
      "14/14 [==============================] - 0s 545us/step - loss: 1903.0248\n",
      "Epoch 289/300\n",
      "14/14 [==============================] - 0s 571us/step - loss: 1923.9875\n",
      "Epoch 290/300\n",
      "14/14 [==============================] - 0s 565us/step - loss: 2000.4119\n",
      "Epoch 291/300\n",
      "14/14 [==============================] - 0s 540us/step - loss: 1930.6924\n",
      "Epoch 292/300\n",
      "14/14 [==============================] - 0s 577us/step - loss: 1909.4630\n",
      "Epoch 293/300\n",
      "14/14 [==============================] - 0s 565us/step - loss: 1881.8798\n",
      "Epoch 294/300\n",
      "14/14 [==============================] - 0s 614us/step - loss: 1960.9135\n",
      "Epoch 295/300\n",
      "14/14 [==============================] - 0s 547us/step - loss: 2011.9674\n",
      "Epoch 296/300\n",
      "14/14 [==============================] - 0s 582us/step - loss: 1962.0679\n",
      "Epoch 297/300\n",
      "14/14 [==============================] - 0s 573us/step - loss: 1897.3971\n",
      "Epoch 298/300\n",
      "14/14 [==============================] - 0s 557us/step - loss: 1878.2719\n",
      "Epoch 299/300\n",
      "14/14 [==============================] - 0s 554us/step - loss: 1889.1852\n",
      "Epoch 300/300\n",
      "14/14 [==============================] - 0s 580us/step - loss: 1954.2274\n",
      "1/1 [==============================] - 0s 57ms/step\n",
      "[203.54877   20.219824 104.92247  117.740715  33.974667 206.2037\n",
      "  59.76753  130.19366  200.98221   57.75394 ]\n"
     ]
    }
   ],
   "source": [
    "model.fit(X_train, y_train, epochs=300)\n",
    "\n",
    "\n",
    "predictions = model.predict(X_test)[:, 0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e5290d7a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[203.54877   20.219824 104.92247  117.740715  33.974667 206.2037\n",
      "  59.76753  130.19366  200.98221   57.75394 ]\n",
      "1294.3979079622677\n"
     ]
    }
   ],
   "source": [
    "print(predictions)\n",
    "print(np.mean((y_test - predictions) ** 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce63d320",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
